---
title: "Data Analysis Report"
output:
  pdf_document: default
  html_document:
    df_print: paged
  word_document: default
---

```{r dependencies, include=FALSE}
#knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(ggplot2)

```

***

# Trees
a) Investigate whether the tree type influences volume by performing ANOVA, without taking diameter and height into account. Can a t-test be related to the above ANOVA test? Estimate the volumes for the two tree types.

```{r}
# Load the data and calculate the mean volume for each tree type

data <- read.table("resources/treeVolume.txt", header=TRUE)
mean_vol_beech <- mean(data[data$type == "beech", "volume"])
mean_vol_oak <- mean(data[data$type == "oak", "volume"])
```

We use the aov() function to perform ANOVA:

```{r}
aov_result <- aov(volume ~ type, data=data)
summary(aov_result)
```

The output of the summary function shows the results of the ANOVA test. When the p-value is below the given confidence level (0.05), we can conclude that there is a significant difference in volumes between the two tree types.

We can see that the p-value is 0.174. Therefore we can conclude that there is not a significant difference in volumes between the two tree types.

It is possible to relate the ANOVA test to a t-test by performing a two-sample t-test between the volumes of the two tree types. However, the ANOVA test is more appropriate when we have more than two groups to compare.

It is possible to relate an ANOVA test to a t-testby performing a two-sample t-test between the volumes of the two tree types. However, the ANOVA test is more appropriate when we have more than two groups to compare.

To perform a t-test, we can use the t.test() function:
```{r}
t_test_result <- t.test(data[data$type == "beech", "volume"], data[data$type == "oak", "volume"])
t_test_result
```

The p-value from the t-test is 0.1659. Relatively similar result to ANOVA performed earlier. The t-test shows us if there is a significant difference in mean volume between the two tree types. With the result we can again say that there is not a significant difference in volumes between the two tree types.

To calculate the mean value of each group we estimate the volumes for each of the tree types.
```{r}
# calculate mean volumes for each tree type
mean_volumes <- tapply(data$volume, data$type, mean)
mean_volumes
```

b)  Now include diameter and height as explanatory variables into the analysis. Investigate whether the influence of diameter on volume is similar for the both tree types. Do the same for the influence of height on volume. (Consider at most one (relevant) pairwise interaction per model.) Comment.

To investigate the influence of diameter and height on volume, we can perform a multiple linear regression analysis in R. We can start by creating a model that includes both diameter and height as explanatory variables:

```{r}
# create multiple linear regression model
reg_model <- lm(volume ~ type + diameter + height, data = data)
summary(reg_model)
```

This code will create a multiple linear regression model using the lm() function in R and display the results using the summary() function. The output will show the coefficients for each variable and their significance.

To investigate whether the influence of diameter on volume is similar for the both tree types, we can include a diameter-tree type interaction term in the model:
```{r}
# create multiple linear regression model with interaction term
reg_model_interaction <- lm(volume ~ type * diameter + height, data = data)
summary(reg_model_interaction)
```

This code will create a new regression model with an interaction term between tree type and diameter, and display the results using the summary() function. We can see that the interaction term is not significant (0.474 > 0.05), therefore, the relationship between diameter and volume does not depend on the tree type.

We can perform a similar analysis to investigate the influence of height on volume:
```{r}
# create multiple linear regression model with interaction term
reg_model_interaction <- lm(volume ~ type + diameter + height * type, data = data)
summary(reg_model_interaction)
```

This code will create a new regression model with an interaction term between tree type and height, and display the results using the summary() function. We can see that the interaction term is not significant (0.17613 > 0.05), therefore, the relationship between height and volume does not depend on the tree type.

In conclusion, by including diameter and height as explanatory variables, we can see that both variables do not have a significant influence on volume, and that the relationships between these variables and volume do not depend on the tree type.

c)  Using the results from c), investigate how diameter, height and type influence volume. Comment. Using the resulting model, predict the volume for a tree with the (overall) average diameter and height?

Using the results from b), we can fit a linear regression model for volume using diameter, height, and type as explanatory variables:
```{r}
lm_all <- lm(volume ~ diameter + height + type, data=data)
summary(lm_all)
```
The results show that diameter and height have a significant influence on volume. Type does not have a significant influence on volume.

To predict the volume for a tree with the overall average diameter and height, we can calculate the mean values for diameter and height and use them in the model:
```{r}
mean_diam <- mean(data$diameter)
mean_height <- mean(data$height)

predicted_vol <- predict(lm_all, newdata=data.frame(diameter=mean_diam, height=mean_height, type="beech"))
predicted_vol
```

d)  Propose a transformation of the explanatory variables that possibly yields a better model (verify this).  (Hint: think of a natural link between the response and explanatory variables.)

One possible transformation of the explanatory variables is to take the natural logarithm of the diameter and height. This transformation can be useful when the relationship between the explanatory variables and the response is not linear but instead follows a logarithmic pattern. We can apply this transformation by creating new variables in the data frame:

```{r}
data$log_diameter <- log(data$diameter)
data$log_height <- log(data$height)
```
Then, we can build a new model using these transformed variables:
```{r}
model2 <- lm(volume ~ log_diameter + log_height + type, data = data)
summary(model2)
```
We can compare the R-squared values of the two models to see which one is a better fit. If the R-squared value for model2 is higher, then the logarithmic transformation improved the model fit. If not, then the original model may be the better choice.

# Expenditure on criminal activities
## Question 2
### a) Make some graphical summaries of the data. Investigate the problem of influence points, and the problem of collinearity.
```{r}
crime_df <- as.data.frame(read.table("resources/expensescrime.txt", header=TRUE))
head(crime_df)
response <- "expend"
exp_vars <- c("bad", "crime", "lawyers", "employ", "pop")
```
### The first step to investigate the data is to plot paired scatterplots for all possible combinations of variables
```{r, echo=FALSE, fig.height=5}
pairs(crime_df[, c(response, exp_vars)])
```
### The response variable 'expend' shows a correlation with all of the variables except for 'crime'. We also observe outliers within the larger integers in the data (towards the end of the plots). There is collinearity between the variables of 'bad', 'lawyers', 'employ' and 'pop'. This makes it hard to estimate the regression coefficients. Cook's distance is then used to find the influence points, we can observe outliers if the distance is larger than 1. 
```{r}
crimelm <- lm(expend~bad+crime+lawyers+employ+pop, data=crime_df)
cooks.distance(crimelm)[cooks.distance(crimelm) > 1]
```
```{r, include=FALSE}
plot(cooks.distance(crimelm), type='b', ylab="Cook's distance", main = "Cook's distance for expensecrime.txt")
```
### The values of 5, 8, 35 and 44 are shown to be outliers, and therefore they are removed. 
```{r}
crime_df_upd <- crime_df[-c(5,8,35,44),]
```
### To further analyse collinearity, we can check the correlations between all the explanatory variables, which indeed shows strong correlations between 'bad', 'lawyers', 'employ' and 'pop'.
```{r}
round(cor(crime_df[, c(exp_vars)]), 2)
```

### We also use VIF to investigate which variables are collinear (a VIF larger than 5 may be concerning).

```{r, include=FALSE}
library(car)
```
```{r}
vif(lm(expend~bad+crime+lawyers+employ+pop, data=crime_df))
```
### This is additional confirmation for collinearity between the variables
### b) Fit a linear regression model to the data. Use the step-up method to find the best model. Comment.
```{r, include=FALSE}
print("Step 1")
print("bad")
summary(lm(expend~bad, data=crime_df))
print("crime")
summary(lm(expend~crime, data=crime_df))
print("lawyers")
summary(lm(expend~lawyers, data=crime_df))
print("employ")
summary(lm(expend~employ, data=crime_df)) # YES
print("pop")
summary(lm(expend~pop, data=crime_df)) 
```
```{r, include=FALSE}
print("Step 2")
print("bad")
summary(lm(expend~employ+bad, data=crime_df))
print("crime")
summary(lm(expend~employ+crime, data=crime_df)) # YES
print("lawyers")
summary(lm(expend~employ+lawyers, data=crime_df))
print("pop")
summary(lm(expend~employ+pop, data=crime_df))
```

```{r, include=FALSE}
print("Step 3")
print("bad")
summary(lm(expend~employ+crime+bad, data=crime_df))
print("lawyers")
summary(lm(expend~employ+crime+lawyers, data=crime_df))
print("pop")
summary(lm(expend~employ+crime+pop, data=crime_df)) # YES
```

```{r, include=FALSE}
print("Step 4")
print("bad")
summary(lm(expend~employ+crime+pop+bad, data=crime_df))
print("lawyers")
summary(lm(expend~employ+crime+pop+lawyers, data=crime_df))
```
### The step-up procedure is carried out. The variables were added in the following order: 'employ', 'crime' and 'pop', after this, no further added variables had significant p-values. Therefore, we come to the final model:
```{r}
step_up_lm <- lm(expend~employ+crime+pop, data=crime_df)
summary(step_up_lm)
```
```{r}
vif(step_up_lm)
```
### We see that the step-up method naturally removes collinearity and produces a better model than the one produced using VIF, which had an R-squared value of 0.957.

Finally, we check the model assumptions, which can be accepted based on the following plots:

```{r, echo=FALSE}
par(mfrow=c(1,2))
qqnorm(residuals(step_up_lm))
plot(fitted(step_up_lm), residuals(step_up_lm))
```
### c) Determine a 95% prediction interval for the expend using the model you preferred in b) for a (hypothetical) state with bad=50, crime=5000, lawyers=5000, employ=5000 and pop=5000. Can you improve this interval?
### Using the step-up model from question 2b, the 95% prediction interval for 'expend' is found by:
```{r}
new_data <- data.frame(bad=50, crime=5000, lawyers=5000, employ=5000, pop=5000)
predict(step_up_lm, new_data, interval="prediction", level=0.95)
```
### This interval can't be improved since the influence points are already removed from the data
```{r, include=FALSE}
predict(step_up_lm, new_data, interval="confidence", level=0.95)
```
### d) Apply the LASSO method to choose the relevant variables (with default parameters as in the lecture and lambda=lambda.1se). (You will need to install the R-package glmnet, which is not included in the standard distribution of R.) Compare the resulting model with the model obtained in b). (Beware that in general a new run delivers a new model because of a new train set.)
### implementation of the LASSO method:
```{r, include=FALSE}
library(glmnet)
```
```{r}
x <- as.matrix(crime_df[, exp_vars])
y <- as.matrix(crime_df[, c(response)])
train <- (sample(1:nrow(x), 0.67*nrow(x))) 
x.train <- x[train,]; y.train <- y[train]
x.test <- x[-train,]; y.test <- y[-train]
lasso.mod <- glmnet(x.train, y.train, alpha=1)
cv.lasso <- cv.glmnet(x.train,y.train,alpha=1,type.measure='mse')
```
```{r}
plot(lasso.mod, label=T, xvar="lambda")  
```
```{r}
plot(cv.lasso) 
```

```{r}
(lambda.1se <- cv.lasso$lambda.1se)
```

```{r}
assess.glmnet(lasso.mod, newx = x.test, newy = y.test, s=cv.lasso$lambda.1se)
```
### Finding lambda 1se
```{r}
coef(lasso.mod, s=cv.lasso$lambda.1se) 
y.pred <- predict(lasso.mod, s=lambda.1se, newx=x.test) 
mse.lasso <- mean((y.test - y.pred)^2); mse.lasso 
```
### We compare this to the step-up model by finding the MSE.
```{r}
new_data <- data.frame(x.test)
y.pred <- predict(step_up_lm, new_data, interval="confidence", level=0.95)
mse.step_up <- mean((y.test - y.pred)^2); mse.step_up 
```
### We find that the step-up model outperforms the LASSO model, giving a smaller MSE. This may be because LASSO is better fitted to situations with much more explanatory variables.


# Titanic

```{r setup_titanic, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
titanic <- read.table("resources/titanic.txt", header = TRUE)
```

## a) Overview + liniar model for Survival

### Survival based on Sex and PClass

```{r}
titanic %>%
  mutate(Survived = factor(Survived, labels = c("Died", "Survived"))) %>% 
  ggplot(aes(x = Sex, fill = Survived)) +
  geom_bar() +
  facet_wrap(~PClass) +
  labs(
    title = "Survival by Sex and PClass",
    x = "Sex",
    y = "Count",
    fill = "Survival Status"
  )
```

### Survival based on Age with respect to Sex and PClass
```{r}
titanic %>%
  mutate(Survived = factor(Survived, labels = c("Died", "Survived"))) %>% 
  ggplot(aes(x = Age, fill = Survived)) +
  geom_density(alpha = 0.5) +
  facet_wrap(~Sex + PClass) +
  labs(x = "Age",
       y = "Count",
       title = "Survival by Age with respect to Sex and PClass",
       fill = "Survival Status")
```


We will fit a liniar model, having `Survived` as the effect and, independently, `PClass`, `Age` and `Sex` as possible causes.

```{r}
model <- glm(Survived ~ PClass + Age + Sex, data = titanic, family = binomial)
model_summary <- summary(model)$coefficients
model_summary
```

```{r}
age_effect_estimate <- summary(model)$coefficients["Age", "Estimate"]
age_p_value <- summary(model)$coefficients["Age", "Pr(>|z|)"]

pclass2nd_p_value <- summary(model)$coefficients["PClass2nd", "Pr(>|z|)"]
pclass3nd_p_value <- summary(model)$coefficients["PClass3rd", "Pr(>|z|)"]
sexmale_p_value <- summary(model)$coefficients["Sexmale", "Pr(>|z|)"]
```


We observe a low p_value (`r age_p_value`) for Age, therefore were reject the initial hypothesis and conclude that age has an effect on the Survival. Apparently, the chances of survival change with (`r age_effect_estimate`) with each year.

We observe a low p_values for PClass2nd (`r pclass2nd_p_value`), PClass3rd (`r pclass3nd_p_value`), Sexmale (`r sexmale_p_value`), therefore were reject the initial hypothesis and conclude that being 2nd class, 3rd class or being a male has an effect on the Survival. 

## b) Interactions + Studying a 55 years old person chances to survive

### Interactions

#### Age * PClass interaction

```{r}
model_age_pclass <- glm(Survived ~ Age:PClass, data = titanic, family = "binomial")
age_first_class = summary(model_age_pclass)$coefficients["Age:PClass1st", "Pr(>|z|)"]
age_second_class = summary(model_age_pclass)$coefficients["Age:PClass2nd", "Pr(>|z|)"]
age_third_class = summary(model_age_pclass)$coefficients["Age:PClass3rd", "Pr(>|z|)"]
```

Big P value (> 0.05) for Age:PClass1st (`r age_first_class`) suggest there is no strong evidence of an interaction between age and 1st class when we observe the survival rates.

Low P values (<< 0.05) for Age:PClass2nd (`r age_second_class`) and Age:PClass3rd (`r age_third_class`)  suggest there is strong evidence of an interaction between age and 2nd/3rd class when we observe the survival rates.

#### Age * Sex interaction
```{r}
model_age_sex <- glm(Survived ~ Age:Sex, data = titanic, family = "binomial")
age_female = summary(model_age_sex)$coefficients["Age:Sexfemale", "Pr(>|z|)"]
age_male = summary(model_age_sex)$coefficients["Age:Sexmale", "Pr(>|z|)"]
```
Low P values (<< 0.05) for Age:Sexfemale (`r age_female`) and Age:Sexmale (age_male) suggest there is strong evidence of an interaction between age and the sex of the passenger

### Hypothetical of a 55 years old person

We build a linear model to predict `Survival` with respect to `Age`, `PClass`, `Sex` and their interactions.
```{r}
model <- glm(Survived ~ Age*PClass*Sex, data = titanic, family = "binomial")
male_first <- predict(model, data.frame(Age = 55, PClass = "1st", Sex = "male"), type = "response") 
male_second <- predict(model, data.frame(Age = 55, PClass = "2nd", Sex = "male"), type = "response") 
male_third <- predict(model, data.frame(Age = 55, PClass = "3rd", Sex = "male"), type = "response") 

female_first <- predict(model, data.frame(Age = 55, PClass = "1st", Sex = "female"), type = "response") 
female_second <- predict(model, data.frame(Age = 55, PClass = "2nd", Sex = "female"), type = "response") 
female_third <- predict(model, data.frame(Age = 55, PClass = "3rd", Sex = "female"), type = "response") 
```

  * Male
    + 55 years old `male` of `1st` class has a change of `r male_first * 100`% to survive.
    + 55 years old `male` of `2nd` class has a change of `r male_second * 100`% to survive.
    + 55 years old `male` of `3rd` class has a change of `r male_third * 100`% to survive.

  * Female
    + 55 years old `female` of `1st` class has a change of `r female_first * 100`% to survive.
    + 55 years old `female` of `2nd` class has a change of `r female_second * 100`% to survive.
    + 55 years old `female` of `3rd` class has a change of `r female_third * 100`% to survive.

Based on previous predictions we argue that a 1st class 55 years old female `r female_first * 100`% was very likely to survive, while a 2nd class 55 years old male (`r female_first * 100`%) would have likely died.

## c) Survival status predictor + quality measures

I would use a random forest classifier as a predictor.

First I would fill in the missing data with following heuristic:

  * Average age for the missing values on `Age` column.
  
  * 50% male/female for missing values on `Sex` column.

We could use cross-validation to split the dataset into train/test datasets.

Python implementation is pretty straightforward with the usage of sklearn.ensemble.RandomForestClassifier class.
As quality measures we could use:

  * precision [`TP / (TP + FP)`]
  
  * recall [`TP/ (TP + FN)`]
  
  * accuracy [`(TP + TN) / ALL`]
 
Due to the stochastic nature of the heuristic chosen for filling in `Sex` column and cross-validation dataset splits, I argue the following:

    * Multiple experiments should be  with respect to cross-validation heuristic.
    * The deviation of the `precision`, `recall` and `accuracy` values should be analysed.

## d) Contingency table test

We will perform two `chi-squared` tests of independence:

### Association between `Survival` and `PClass` 
```{r}
class_survival_p_value = chisq.test(table(titanic$Survived, titanic$PClass))$p.value 
```

We observe a small (<< 0.05) P value (`r class_survival_p_value`) for our test, therefore, we reject the null hypothesis and conclude that there is evidence of an association between the `Survival` and `PClass`.

### Association between `Survival` and `Sex` 
```{r}
sex_survival_p_value = chisq.test(table(titanic$Survived, titanic$Sex))$p.value 
```

We observe a small (<< 0.05) P value (`r sex_survival_p_value`) for our test, therefore, we reject the null hypothesis and conclude that there is evidence of an association between the `Survival` and `Sex`.

## e) `random forest classifier` vs `chi-squared` independence test.

`chi-squared` test provides a statistical significance test to check association between `Survival` and (`PClass` | `Sex`).
It was useful and fast to get insights over the dataset and to statistically derive the association between (`PClass` | `Sex`) and `Survival`.

Arguably, `random forest classifier` offers a predictive model which can be used for extensive analysis.

Both methods serve their purposes in a complementary way.

# Military Coups
## a)  Perform Poisson regression on the full data set, taking miltcoup as response variable. Comment on your findings.

To perform Poisson regression in R, we first need to load the coups.txt file into a data frame. Then, we can use the glm() function to fit a Poisson regression model with miltcoup as the response variable and all other variables as predictors. 

```{r}
# Load the data
coups <- read.table("resources/coups.txt", header=TRUE)

# Fit the Poisson regression model
model <- glm(miltcoup ~ oligarchy + pollib + parties + pctvote + popn + size + numelec + numregim, data=coups, family="poisson")
# or model <- glm(miltcoup ~ ., data = coups, family = "poisson")

# Print the model summary
summary(model)
```

The family argument specifies the type of model to fit. In this case, we want a Poisson regression model, so we set family = "poisson".

The output of the summary() function will show us the estimated coefficients, standard errors, z-values, and p-values for each predictor variable in the model. We can use these values to interpret the effect of each predictor on the number of successful military coups.

Based on the p-values, we see that the variables oligarchy, pollib, and parties are significant at the 0.05 level. This means that these variables are likely to be important predictors of the number of military coups.

The coefficient for the variable "oligarchy" is positive and statistically significant (i.e., the p-value is less than 0.05). Therefore, we can conclude that countries with more years ruled by a military oligarchy are more likely to have experienced successful military coups. Moreover, the coefficient for the variable "pollib" is negatively and statistically significant. We can therefore conclude that countries with more political liberalization (i.e., full civil rights) are less likely to have experienced successful military coups.

The coefficient for parties is negative and statistically significant, which means that as the number of legal political parties increases, the number of military coups tends to decrease.

## b)
```{r, include=FALSE}
step1 <- glm(miltcoup ~ oligarchy + parties + pctvote + popn + size + numelec + pollib, data = coups, family = poisson)
drop1(step1, test="Chisq")
```

```{r, include=FALSE}
step2 <- glm(miltcoup ~ oligarchy + parties + pctvote + popn + size + pollib, data = coups, family = poisson)
drop1(step2, test="Chisq")
```

```{r, include=FALSE}
step3 <- glm(miltcoup ~ oligarchy + parties + pctvote + popn + pollib, data = coups)
drop1(step3, test="Chisq")
```

```{r, include=FALSE}
step4 <- glm(miltcoup ~ oligarchy + parties + popn + pollib, data = coups)
drop1(step4, test="Chisq")
```

```{r, include=FALSE}
step5 <- glm(miltcoup ~ oligarchy + parties + pollib, data = coups, family = poisson)
drop1(step5, test="Chisq")
```

The step down method was applied, which removes the variables: numelec, size, pctvote, and popn, respectively. After this, all of the remaining variables were significant, resulting in the model:

```{r}
final_plm <- glm(miltcoup ~ oligarchy + parties + pollib, data = coups, family = poisson)
summary(final_plm, test="Chisq")
```

All of the variables show significance when compared to 4a). 

## c)

```{r}
coups$pollib <- as.factor(coups$pollib)
```

```{r}
mean(coups$oligarchy); mean(coups$parties)
```


```{r}
newdata <- data.frame(pollib=c(0, 1, 2), oligarchy=c(5.22, 5.22, 5.22), parties=c(17.1, 17.1, 17.1))
predict(final_plm, newdata, type="response")
```

The model predicts that there will be approximately 3 successful coups for pollib=0, roughly 2 successful coups for pollib=1, and 1 successful coup for pollib=2.

***
***
***
