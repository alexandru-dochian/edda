---
title: "R Assignment"
output: html_notebook
---
```{r}
print(birthweight$birthweight)
```
# 1A
```{r}
sample_mean <- mean(birthweight$birthweight)
mean(sample_mean)
```

```{r}
sample_sd <- sd(birthweight$birthweight)
print(sample_sd)
n = 188

```
# Checking normality 
```{r}
dataset_hist <- hist(birthweight$birthweight, main= 'Distribution of Birthweight')
print(dataset_hist)
dataset_qq <- qqnorm(birthweight$birthweight, main = 'Normal Q-Q Plot')
print(dataset_qq)
box_plot <- boxplot(birthweight$birthweight)
shap_val <- shapiro.test(birthweight$birthweight)
print(shap_val)
```
# The data from the histogram and the Q-Q plot indicates that the dataset has normality, the histogram and box-plot follow the shape of a normal distribution. The Q-Q plot shows perfect normality. The Shapiro-wilk test provides a p-value of: 0.8995. The test doesn't reject normality 

# Bootstrap test:
```{r}
library(boot)
set.seed(123)
gen_data <- rnorm(1000, mean = sample_mean, sd = sample_sd)

boot_mean <- function(data, index) {
  return(mean(data[index]))
}
 
boot_results <- boot(data = gen_data, statistic = boot_mean, R = 1000)

boot_CI <- quantile(boot_results$t, c(0.02, 0.98))

cat("Bootstrap 96% CI for the mean: [", boot_CI , "]")
```
# The bootstrap 96% CI is in between [2881.533, 2969.063]

# Bounded 96% CI for the mean 
```{r}
standard_error <- sample_sd / sqrt(188)
```
```{r}
t_value <- qt(0.98, 187)
lower_bound <- sample_mean - (t_value * standard_error)
upper_bound <- sample_mean + (t_value * standard_error)
cat(round(lower_bound, 2), round(upper_bound, 2))
```
# The bounded 96% CI is between [2808.1, 3018.5]

# Calculating sample size for length of 96% CI being at most 100
```{r}
margin_of_error <- 50
t_value <- qt(0.98, df = 187)
nn <- ceiling((t_value * sample_sd / margin_of_error) ^ 2)
cat("The sample size needed to ensure that the length of the 96% CI is at most 100 is ", nn)
```
# 1B

# The sample size required is 833 

# t-test
```{r}
alpha <- 0.05
claim_value <- 2800
t_result <- t.test(birthweight$birthweight, mu = claim_value, alternative = "greater", conf.level = 0.95)
p_value_t <- t_result$p.value
print(t_result)
```
# The results of this t-test indicate that the true mean (2829.2) is in fact larger than 2800, this was shown through the p-value which was significant 0.01357<0.05. Therefore, the null hypothesis can be rejected. 

# sign test 
```{r}
sum_sign <- sum(birthweight$birthweight > 2800)
sign_test <- binom.test(107, 188, p = 0.5, conf.level = 0.96, alternative = "greater")
p_value_sign <- sign_test$p.value
print(sign_test)
```
#This verifies the claim of the expert, the evidence is statistically significant, the p-value is less than 0.05 (0.03399).
#Both of the tests indicated that the H0 can be rejected. 

# 1C

# Power can be referred to as the level of precision of a test correctly rejecting the null hypothesis
# Power of the tests:to compute the power of the tests we use simulation which can calculate the amount of times that the alpha is <0.05 when repeating 1000 times. 
# t-test
```{r}
library("pwr")
mu <- 2900
sd <- sample_sd
alpha <- 0.05
d <- (mu - 2800) / sd
power <- pwr.t.test(nn, d=d, sig.level=alpha, type="one.sample", alternative="greater")$power
cat("The power of the one-sample t-test is", round(power, 4))
```
# The power of the t-test is 0.9936, this indicates a high power, which allows us to reject H0 correctly with an accuracy of 99.36%, the test has a high sensitivity and can detect a true difference between the true mean and hypothesized value. (This is just an extra test before doing the simulation)

# comparing both tests                                   
```{r}
set.seed(123)
B = 1000
n = 188
psign = numeric(B)
pttest = numeric(B)
for (i in 1:B) {
  x = sample(birthweight$birthweight, n, replace = TRUE)
  pttest[i] = t.test(x)$p.value
  psign[i] = binom.test(sum(x > mean(birthweight$birthweight)), n, p = 0.5, alternative = "greater")$p.value
} 
sum(psign < 0.05)
sum(pttest < 0.05)

```
# The t-test has much more power than the sign test in comparison, it's extremely accurate since the simulation produced the result of 1000/1000 alpha<0.05 being produced for the t-test, whereas only 15/1000 for the sign test, which is very weak in comparison. 

# 1D

```{r}
z2600 = (2600 - sample_mean)/sample_sd
p2600 <- pnorm(z2600)
print(p2600)
# z value for left side
z_l <- qnorm(0.25)
#p for right side
z_r <- z2600 + (z2600-z_l)
p_r <- pnorm(z_r)
print(p_r)

```
# CI of p: [0.25,0.41]. 
# Calculating the confidence level:
# We can use the Z-table to further confirm that the p-hat value for the right side is 0.41, this has a z-score of 2.32, consequently providing the confidence level as 98%
```{r}
tval_98 <- qt(0.01, 187, lower.tail = FALSE)
tval_98
```
# The output indicates that the 98% confidence interval for babies weight <2600 is: [0.25,0.41]

# 1E

```{r}
m1 <- rep(c("M"), 34)
f1 <- rep(c("F"), 28)
both <- c(m1, f1)
m2 <- rep(c("M"), 61)
f2 <- rep(c("F"), 65)
both_2 <- c(m2, f2)
weight_all <- c(rep(1, 62), rep(2, 126))

# compute two sample t-test, we find the significance for the differences in mean weight 
weight_ttest <- t.test(weight_all ~ c(both, both_2), var.equal = TRUE)
cat("p-value for the t-test is:", weight_ttest$p.value)
```
# The t-test provides us with a p-value of 0.41, which indicates that there is no statistical significance, since it is above alpha of 0.05 by a big difference, this allows us to conclude that the mean weight between males and females does not differ 


```{r}
lm = lm(yield ~., data = npk)
step_model <- stepAIC(lm, direction = "both")
```
```{r}
lm2 = lm(formula = yield ~ block + N + K + block*N, data = npk)
lm3 = lm(formula = yield ~ block + N + block*K, data = npk)
```



