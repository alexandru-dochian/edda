---
title: "Data Analysis Report"
output:
  pdf_document: default
  html_document:
    df_print: paged
  word_document: default
---

```{r dependencies, include=FALSE}
#knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(ggplot2)

```

***

# Titanic

```{r setup_titanic, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
titanic <- read.table("resources/titanic.txt", header = TRUE)
```

## a) Overview + liniar model for Survival

### Survival based on Sex and PClass

```{r}
titanic %>%
  mutate(Survived = factor(Survived, labels = c("Died", "Survived"))) %>% 
  ggplot(aes(x = Sex, fill = Survived)) +
  geom_bar() +
  facet_wrap(~PClass) +
  labs(
    title = "Survival by Sex and PClass",
    x = "Sex",
    y = "Count",
    fill = "Survival Status"
  )
```

### Survival based on Age with respect to Sex and PClass
```{r}
titanic %>%
  mutate(Survived = factor(Survived, labels = c("Died", "Survived"))) %>% 
  ggplot(aes(x = Age, fill = Survived)) +
  geom_density(alpha = 0.5) +
  facet_wrap(~Sex + PClass) +
  labs(x = "Age",
       y = "Count",
       title = "Survival by Age with respect to Sex and PClass",
       fill = "Survival Status")
```


We will fit a liniar model, having `Survived` as the effect and, independently, `PClass`, `Age` and `Sex` as possible causes.

```{r}
model <- glm(Survived ~ PClass + Age + Sex, data = titanic, family = binomial)
model_summary <- summary(model)$coefficients
model_summary
```

```{r}
age_effect_estimate <- summary(model)$coefficients["Age", "Estimate"]
age_p_value <- summary(model)$coefficients["Age", "Pr(>|z|)"]

pclass2nd_p_value <- summary(model)$coefficients["PClass2nd", "Pr(>|z|)"]
pclass3nd_p_value <- summary(model)$coefficients["PClass3rd", "Pr(>|z|)"]
sexmale_p_value <- summary(model)$coefficients["Sexmale", "Pr(>|z|)"]
```


We observe a low p_value (`r age_p_value`) for Age, therefore were reject the initial hypothesis and conclude that age has an effect on the Survival. Apparently, the chances of survival change with (`r age_effect_estimate`) with each year.

We observe a low p_values for PClass2nd (`r pclass2nd_p_value`), PClass3rd (`r pclass3nd_p_value`), Sexmale (`r sexmale_p_value`), therefore were reject the initial hypothesis and conclude that being 2nd class, 3rd class or being a male has an effect on the Survival. 

## b) Interactions + Studying a 55 years old person chances to survive

### Interactions

#### Age * PClass interaction

```{r}
model_age_pclass <- glm(Survived ~ Age:PClass, data = titanic, family = "binomial")
age_first_class = summary(model_age_pclass)$coefficients["Age:PClass1st", "Pr(>|z|)"]
age_second_class = summary(model_age_pclass)$coefficients["Age:PClass2nd", "Pr(>|z|)"]
age_third_class = summary(model_age_pclass)$coefficients["Age:PClass3rd", "Pr(>|z|)"]
```

Big P values (> 0.05) for Age:PClass1st (`r age_first_class`) and Age:PClass3rd (`r age_third_class`) suggest there is no strong evidence of an interaction between age and those classes passengers.

Low P value (<< 0.05) for Age:PClass2nd (`r age_second_class`) suggest therestrong evidence of an interaction between age and 2nd class of passengers.

#### Age * Sex interaction
```{r}
model_age_sex <- glm(Survived ~ Age:Sex, data = titanic, family = "binomial")
age_female = summary(model_age_sex)$coefficients["Age:Sexfemale", "Pr(>|z|)"]
age_male = summary(model_age_sex)$coefficients["Age:Sexmale", "Pr(>|z|)"]
```
Low P values (<< 0.05) for Age:Sexfemale (`r age_female`) and Age:Sexmale (age_male) suggest there is strong evidence of an interaction between age and the sex of the passenger

### Hypothetical of a 55 years old person

We build a linear model to predict `Survival` with respect to `Age`, `PClass`, `Sex` and their interactions.
```{r}
model <- glm(Survived ~ Age*PClass*Sex, data = titanic, family = "binomial")
male_first <- predict(model, data.frame(Age = 55, PClass = "1st", Sex = "male"), type = "response") 
male_second <- predict(model, data.frame(Age = 55, PClass = "2nd", Sex = "male"), type = "response") 
male_third <- predict(model, data.frame(Age = 55, PClass = "3rd", Sex = "male"), type = "response") 

female_first <- predict(model, data.frame(Age = 55, PClass = "1st", Sex = "female"), type = "response") 
female_second <- predict(model, data.frame(Age = 55, PClass = "2nd", Sex = "female"), type = "response") 
female_third <- predict(model, data.frame(Age = 55, PClass = "3rd", Sex = "female"), type = "response") 
```

  * Male
    + 55 years old `male` of `1st` class has a change of `r male_first * 100`% to survive.
    + 55 years old `male` of `2nd` class has a change of `r male_second * 100`% to survive.
    + 55 years old `male` of `3rd` class has a change of `r male_third * 100`% to survive.

  * Female
    + 55 years old `female` of `1st` class has a change of `r female_first * 100`% to survive.
    + 55 years old `female` of `2nd` class has a change of `r female_second * 100`% to survive.
    + 55 years old `female` of `3rd` class has a change of `r female_third * 100`% to survive.

Based on previous predictions we argue that a 1st class 55 years old female `r female_first * 100`% was very likely to survive, while a 2nd class 55 years old male (`r female_first * 100`%) would have likely died.

## c) Survival status predictor + quality measures

I would use a random forest classifier as a predictor.

First I would fill in the missing data with following heuristic:

  * Average age for the missing values on `Age` column.
  
  * 50% male/female for missing values on `Sex` column.

We could use cross-validation to split the dataset into train/test datasets.

Python implementation is pretty straightforward with the usage of sklearn.ensemble.RandomForestClassifier class.
As quality measures we could use:

  * precision [`TP / (TP + FP)`]
  
  * recall [`TP/ (TP + FN)`]
  
  * accuracy [`(TP + TN) / ALL`]
 
Due to the stochastic nature of the heuristic chosen for filling in `Sex` column and cross-validation dataset splits, I argue the following:

    * Multiple experiments should be  with respect to cross-validation heuristic.
    * The deviation of the `precision`, `recall` and `accuracy` values should be analysed.

## d) Contingency table test

We will perform two `chi-squared` tests of independence:

### Association between `Survival` and `PClass` 
```{r}
class_survival_p_value = chisq.test(table(titanic$Survived, titanic$PClass))$p.value 
```

We observe a small (<< 0.05) P value (`r class_survival_p_value`) for our test, therefore, we reject the null hypothesis and conclude that there is evidence of an association between the `Survival` and `PClass`.

### Association between `Survival` and `Sex` 
```{r}
sex_survival_p_value = chisq.test(table(titanic$Survived, titanic$Sex))$p.value 
```

We observe a small (<< 0.05) P value (`r sex_survival_p_value`) for our test, therefore, we reject the null hypothesis and conclude that there is evidence of an association between the `Survival` and `Sex`.

## e) `random forest classifier` vs `chi-squared` independence test.

`chi-squared` test provides a statistical significance test to check association between `Survival` and (`PClass` | `Sex`).
It was useful and fast to get insights over the dataset and to statistically derive the association between (`PClass` | `Sex`) and `Survival`.

Arguably, `random forest classifier` offers a predictive model which can be used for extensive analysis.

Both methods serve their purposes in a complementary way.

***
***
***
